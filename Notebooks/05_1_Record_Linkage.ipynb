{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "Rayid Ghani, Frauke Kreuter, Julia Lane, Adrianne Bradford, Alex Engler, Nicolas Guetta Jeanrenaud, Graham Henke, Daniela Hochfellner, Clayton Hunter, Brian Kim, Avishek Kumar, Jonathan Morgan, Ridhima Sodhi, and Benjamin Feder. \n",
    "\n",
    "_source to be updated when notebook added to GitHub_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Linkage\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "JupyterLab contains a dynamic Table of Contents that can be accessed by clicking the last of the six icons on the left-hand sidebar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook will provide you with an introduction to record linkage using Python. Upon completion of this notebook, you will be able to apply record linkage techniques using the `recordlinkage` package to combine data from different sources in python. You will go through all the steps necessary for a successful record linkage starting with data preparation, which includes pre-processing, cleaning and standardizing data.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "We will explore different record linkage techniques in order to match the `tip_2017` table of WIC-approved vendors with `store_info_all`, which contains general vendor information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Principles of Record Linkage\n",
    "\n",
    "The goal of record linkage is to determine if pairs of records describe the same identity. For instance, this is important for removing duplicates from a data source or joining two separate data sources together. Record linkage also goes by the terms data matching, merge/purge, duplication detection, de-duping, reference matching, entity resolution, disambiguation, co-reference/anaphora in various fields.\n",
    "\n",
    "There are several approaches to record linkage that include:\n",
    "    - exact matching \n",
    "    - rule-based linking \n",
    "    - probabilistic linking \n",
    "- An example of **exact matching** is joining records based on social security number, exact name, or geographic code information. You have already have done this in SQL when joining tables on an unique identifier. \n",
    "- **Rule-based matching** involves applying a cascading set of rules that reflect the domain knowledge of the records being linked. \n",
    "- In **probabilistic record linkages**, linkage weights are estimated to calculate the probability of a certain match.\n",
    "\n",
    "In practical applications, you will need record linkage techniques to combine information addressing the same entity that is stored in different data sources. Record linkage will also help you to address the quality of varying data sources. For example, if one of your databases has missing values, you might be able to fill those by finding an identical pair in a different data source. Overall, the main applications of record linkage are:\n",
    "    1. Merging two or more data files \n",
    "    2. Identifying the intersection of the two data sets \n",
    "    3. Updating data files (with the data row of the other data files) and imputing missing data\n",
    "    4. Entity disambiguation and de-duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Approach\n",
    "\n",
    "For this notebook exercise, we are interested in vendor data.\n",
    "- **Analytical Exercise**: Find WIC-approved stores in the vendor data supplied by IRI. \n",
    "- **Data Availability**: We have names, addresses, and years for the various vendors in the two tables. \n",
    "\n",
    "- **Approach**: We will look at the data available to us and clean & pre-process it to enable better linkage. Afterwards, we will use string matching techniques that are enabled by record linkage package in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the Data\n",
    "\n",
    "Python provides us with some tools we can use for record linkages so we don't have to start from scratch and code our own linkage algorithms. Before we start, we need to load the package `recordlinkage`. We will be adding a few more packages than usual to our import process because the `recordlinkage` package has a few dependencies on other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use imports\n",
    "%pylab inline\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# pandas-related imports\n",
    "import pandas as pd\n",
    "\n",
    "# record linkage package\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.preprocessing import clean\n",
    "\n",
    "# database interaction imports\n",
    "from pyathenajdbc import connect\n",
    "\n",
    "print( \"Imports loaded at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(s3_staging_dir = 's3://usda-iri-2019-queryresults/',\n",
    "               region_name = 'us-gov-west-1',\n",
    "               LogLevel = '0',\n",
    "               workgroup = 'workgroup-iri_usda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "In our notebooks thus far, we have not utilized either `tip_2017` or `store_info_all`. To see what data manipulations we may have to perform, let's take a quick look at the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select *\n",
    "from iri_usda.store_info_all\n",
    "where year = '2017'\n",
    "'''\n",
    "\n",
    "df_total = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null values by column\n",
    "df_total.isnull().sum()\n",
    "# Output: count of null values for all of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.isin(['', '.']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are null values for some columns in `store_info_all` in 2017, they are not in any of the variables that we will be using for the record linkage. Therefore, we will not have to do any manipulation with null values for `store_info_all`. Let's see if we have any extra work for `tip_2017`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select *\n",
    "from iri_usda.tip_2017\n",
    "'''\n",
    "\n",
    "df_approved = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: count of null values for all of the columns\n",
    "df_approved.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved.isin(['', '.']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we were not as lucky for `df_approved`. Let's see what's wrong, i.e. when `vendor_street_number` and/or `vendor_street` are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when street number is missing\n",
    "qry = '''\n",
    "select *\n",
    "from iri_usda.tip_2017\n",
    "where vendor_street_number = ''\n",
    "limit 5\n",
    "'''\n",
    "\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count when all three street identifiers are missing\n",
    "qry = '''\n",
    "select count(*) \n",
    "from iri_usda.tip_2017\n",
    "where vendor_street_number = '' and vendor_street = '' and vendor_additional_address = ''\n",
    "'''\n",
    "\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `store_info_all` only has one column for the street number and address, we will have to concatenate `vendor_street_number` and `vendor_street`. However, we can also see that when `vendor_street_number` and `vendor_street` are null, there is a value for `vendor_additional_address`. Therefore, we will overwrite `df_approved` with a SQL query that concatenates `vendor_street_number` and `vendor_street` when they exist, and otherwise uses `vendor_additional_address`.\n",
    "\n",
    "> In practice, it would be best to separate the street number and name into two separate categories as was described in the lecture. However, that would require additional code and since the purpose of this notebook is to get familiarized with various record linkage techniques, that process will not be covered in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite df_approved with only columns needed for linkage\n",
    "sql = '''\n",
    "select vendor_name, \n",
    "    case when vendor_street_number = '' and vendor_street = '' then vendor_additional_address\n",
    "    else concat(vendor_street_number, ' ',vendor_street)\n",
    "    end as address,\n",
    "vendor_city, vendor_state, vendor_zip\n",
    "from iri_usda.tip_2017\n",
    "'''\n",
    "\n",
    "df_approved = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm df_approved is what we want\n",
    "df_approved.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Importance of Pre-Processing\n",
    "\n",
    "Data pre-processing is an important step in a data analysis project in general, and in record linkage applications, it is particularly crucial. The goal of pre-processing is to transform messy data into a dataset that can be used in a project workflow.\n",
    "\n",
    "Linking records from different data sources comes with different challenges that need to be addressed by the analyst. The analyst must determine whether or not two entities (individuals, businesses, geographical units) from two different files are the same. This determination is not always easy. In most of the cases there is no common uniquely identifing characteristic for a entity. For example, is Bob Miller from New York the same person as Bob Miller from Chicago in a given dataset? This determination has to be executed carefully because consequences of wrong linkages may be substantial (i.e. Is person X the same person as the person X on the list of identified terrorists?). Pre-processing can help to make better informed decisions.\n",
    "\n",
    "Pre-processing can be difficult because there are a lot of things to keep in mind. For example, data input errors, such as typos, misspellings, truncation, abbreviations, and missing values need to be corrected. Literature shows that pre-processing can improve matches. In some situations, 90% of the improvement in matching efficiency may be due to pre-processing. The most common reason why matching projects fail is the lack of time and resources for data cleaning. \n",
    "\n",
    "In the following section, we will walk you through some pre-processing steps. Here we will touch upon practices that include but are not limited to removing spaces, parsing fields, and standardizing strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the the most recurring store names in the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_total['store_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved['vendor_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Right away, we notice that the record linkage between the different datasets will not be straightforward. The variable is messy and non-standardized, similar names can be written differently (in upper-case or lower-case characters, with or without suffixes, etc.) The essential next step is to process the variables in order to make the linkage the most effective and relevant possible.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing String Variables\n",
    "\n",
    "By default, the split method returns a list of strings obtained by splitting the original string on spaces or commas, etc. The record linkage package comes with a build in cleaning function we can also use. In addition, we can extract information from strings for example by using regex search commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppercasing names and creating a new column of names to work with\n",
    "df_total['store_name_clean']=df_total.store_name.str.upper()\n",
    "df_total['address_clean'] = df_total.address.str.upper()\n",
    "df_total['city_clean'] = df_total.city.str.upper()\n",
    "df_total['state_clean'] = df_total.state.str.upper()\n",
    "\n",
    "# Do same to df_approved\n",
    "df_approved['vendor_name_clean'] = df_approved.vendor_name.str.upper()\n",
    "df_approved['address_clean'] = df_approved.address.str.upper()\n",
    "df_approved['vendor_city_clean'] = df_approved.vendor_city.str.upper()\n",
    "df_approved['vendor_state_clean'] = df_approved.vendor_state.str.upper()\n",
    "\n",
    "# see first five entries\n",
    "df_approved.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning names (using the record linkage package tool, see imports)\n",
    "# Clean removes any characters such as '-', '.', '/', '\\', ':', brackets of all types. \n",
    "df_total['store_name_clean']=clean(df_total['store_name_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "df_total['address_clean']=clean(df_total['address_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "df_total['city_clean']=clean(df_total['city_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "df_total['state_clean']=clean(df_total['state_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "\n",
    "# Do same for df_approved\n",
    "df_approved['vendor_name_clean']=clean(df_approved['vendor_name_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "df_approved['address_clean']=clean(df_approved['address_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "df_approved['vendor_city_clean']=clean(df_approved['vendor_city_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "df_approved['vendor_state_clean']=clean(df_approved['vendor_state_clean'], lowercase=False, strip_accents='ascii', \\\n",
    "                                remove_brackets=False)\n",
    "\n",
    "df_total.head()\n",
    "df_approved.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions – `regex`\n",
    "\n",
    "Regular expressions (regex) are a way of searching for a character pattern. They can be used for matching or replacing operations in strings.\n",
    "\n",
    "When defining a regular expression search pattern, it is a good idea to start out by writing down, explicitly, in plain English, what you are trying to search for and exactly how you identify when you've found a match.\n",
    "For example, if we look at an author field formatted as \"&lt;last_name&gt; , &lt;first_name&gt; &lt;middle_name&gt;\", in plain English, this is how I would explain where to find the last name: \"starting from the beginning of the line, take all the characters until you see a comma.\"\n",
    "\n",
    "\n",
    "In a regular expression, there are special reserved characters and character classes. For example:\n",
    "- \"`^`\" matches the beginning of the line or cell\n",
    "- \"`.`\" matches any character\n",
    "- \"`+`\" means one or more repetitions of the preceding expressions\n",
    "\n",
    "Anything that is not a special character or class is just looked for explicitly. A comma, for example, is not a special character in regular expressions, so inserting \"`,`\" in a regular expression will simply match that character in the string.\n",
    "\n",
    "In our example, in order to extract the last name, the resulting regular expression would be:\n",
    "\"`^.+,`\". We start at the beginning of the line ( \"`^`\" ), matching any characters ( \"`.+`\" ) until we come to the literal character of a comma ( \"`,`\" ).\n",
    "\n",
    "\n",
    "> _If you want to actually look for one of these reserved characters, it must be escaped. For example, if the expression looks for a literal period, rather than the special regular expression meaning of a period, precede it with a back slash ( \"`\\`\" ) to escape the reserved character in a regular expression. For example, \"`\\.`\" will match a \"`.`\" character in a string._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REGEX CHEATSHEET__\n",
    "\n",
    "\n",
    "    - abc...     Letters\n",
    "    - 123...     Digits\n",
    "    - \\d         Any Digit\n",
    "    - \\D         Any non-Digit Character\n",
    "    - .          Any Character\n",
    "    - \\.         Period\n",
    "    - [a,b,c]    Only a, b or c\n",
    "    - [^a,b,c]   Not a,b, or c\n",
    "    - [a-z]      Characters a to z\n",
    "    - [0-9]      Numbers 0 to 9\n",
    "    - \\w any     Alphanumeric chracter\n",
    "    - \\W         any non-Alphanumeric character\n",
    "    - {m}        m Repetitions\n",
    "    - {m,n}      m to n repetitions\n",
    "    - *          Zero or more repetitions\n",
    "    - +          One or more repetitions\n",
    "    - ?          Optional Character\n",
    "    - \\s         any Whitespace\n",
    "    - \\S         any non-Whitespace character\n",
    "    - ^...$      Starts & Ends\n",
    "    - (...)      Capture Group\n",
    "    - (a(bc))    Capture sub-Group\n",
    "    - (.*)       Capture All\n",
    "    - (abc|def)  Capture abc or def\n",
    "\n",
    "__Examples:__\n",
    "    - `(\\d\\d|\\D)`      will match 22X, 23G, 56H, etc...\n",
    "    - `(\\w)`           will match any characters between 0-9 or a-z\n",
    "    - `(\\w{1-3})`      will match any alphanumeric character of a length of 1 to 3. \n",
    "    - `(spell|spells)` will match spell or spells\n",
    "    - `(corpo?)        will match corp or corpo\n",
    "    - `(feb 2.)`       will match feb 20, feb 21, feb 2a, etc.\n",
    "\n",
    "__Using REGEX to match characters:__\n",
    "\n",
    "In python, to use a regular expression to search for matches in a given string, we use the built-in \"`re`\" package ( https://docs.python.org/2/library/re.html ), specifically the \"`re.search()`\" method. To use \"`re.search()`\", pass it the regular expression you want to use to search enclosed in quotation marks, and then the string you want to search within. \n",
    "\n",
    "__Using REGEX for replacing characters:__\n",
    "\n",
    "The `re` package also has an \"`re.sub()`\" method used to replace regular expressions by other strings. The method can be applied to an entire pandas column (replacing expression1 with expression2) with the following syntax: `df['variable'].str.replace(r'expression1', 'expression2')`. Note the `r` before the first string to signal we are using regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will not have to use regex too much to pre-process our data tables, but in general, knowing regex is essential for cleaning data. Here, we will show you how you can use regex to extract everything inside quotation marks from addresses in `df_approved`.\n",
    "\n",
    "> The quotation marks were already removed in the previous steps, but this example shows how you can do the same process using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting address inside quotations in df_approved\n",
    "\n",
    "# Pattern1\n",
    "df_approved['address'].str.extract('\"(.*)\"')\n",
    "\n",
    "# Breaking the code down: \n",
    "# .*? ---- tells that we need any character 0 or more times after the first quotation mark\n",
    "# () enclosing brackets tell that we need to extract this information in the new variable\n",
    "# \"\" we need to find everything inside of the quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any other possible standardizations? Insert them below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done with the inital data prep work. Please keep in mind that we just provided some examples for you to demonstrate the process. You can add as many further steps to it as necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Linkage\n",
    "The record linkage package is a quite powerful tool for you to use when you want to link records within a dataset or across multiple datasets. It comes with different bulid in distances metrics and comparison functions, however, it also allows you to create your own. In general record linkage is divided in several steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep variables relevant for linkage\n",
    "df_total = df_total[['store_name_clean', 'zipcode', 'address_clean', 'city_clean', 'state_clean']]\n",
    "df_approved = df_approved[['vendor_name_clean', 'vendor_zip', 'address_clean', 'vendor_city_clean', \n",
    "                           'vendor_state_clean']]\n",
    "\n",
    "#rename df_approved to match df_total for simplicity sake\n",
    "df_approved = df_approved.rename({'vendor_name_clean':'store_name_clean', 'vendor_zip':'zipcode', \n",
    "                                  'vendor_city_clean':'city_clean','vendor_state_clean':'state_clean'}, \n",
    "                                 axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already done the pre-processing, so the next step is indexing the data we would like to link. Indexing allows you to create candidate links, which basically means identifying pairs of data rows which might refer to the same real world entity. This is also called the comparison space (matrix). There are different ways to index data. The easiest is to create a full index and consider every pair a match. This is also the least efficient method, because we will be comparing every row of one dataset with every row of the other dataset. Because of how extensive this process is, we will demonstrate it on just stores in New Mexico to limit its runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to just one state to demonstrate the `FullIndex()` method\n",
    "nm_total = df_total[df_total['state_clean'] == 'NM']\n",
    "nm_approved = df_approved[df_approved['state_clean'] == 'NM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a full index first (comparison table of all possible linkage combinations)\n",
    "indexer = rl.index.Full()\n",
    "pairs = indexer.index(nm_total, nm_approved)\n",
    "# Returns a pandas MultiIndex object\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do better if we actually include our knowledge about the data to eliminate bad links from the start. This can be done through blocking. The `recordlinkage` package gives you multiple options for this. For example, you can block by using variables, which means that only links exactly equal on specified values will be kept. Here, we will block on `zipcode` so we only compare stores with the same zip code. \n",
    "\n",
    "You can also use a neighborhood index in which the rows in your dataframe are ranked by some value and python will only link between the rows that are close by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize indexer\n",
    "indexer = rl.Index()\n",
    "\n",
    "#block on zipcode\n",
    "indexer.block('zipcode')\n",
    "\n",
    "# Returns a pandas MultiIndex object\n",
    "pairs2 = indexerBL.index(df_total, df_approved)\n",
    "print(len(pairs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate compare object (we are using the blocked ones here)\n",
    "# You want to give python the name of the MultiIndex and the names of the datasets\n",
    "compare = rl.Compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set up our comparison space. We can start to compare our files and see if we find matches. We will demonstrate an exact match and rule based approches using distance measures. Our goal is to create a dataframe for each record pair and if they are listed as a match using different linking methods. To do so, we will include the `label` argument to store the algorithms' outputs as different variables in our dataframe. \n",
    "\n",
    "As for the different comparative measures we will cover, they include:\n",
    "- Exact\n",
    "- Levenshtein\n",
    "- Jarowinkler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact comparison\n",
    "# This compares all the pairs of strings for exact matches \n",
    "# It is similar to a JOIN-- \n",
    "compare.exact('store_name_clean','store_name_clean', label = 'store_name_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command gives us the probability of match between two strings based on the levenshtein distance\n",
    "# The measure is 0 if there are no similarities in thee string, 1 if it's identical  \n",
    "compare.string('store_name_clean','store_name_clean', method='levenshtein', label = 'levenshtein_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command gives us the probability of match between two strings based on the jarowinkler distance\n",
    "# The measure is 0 if there are no similarities in thee string, 1 if it's identical \n",
    "compare.string('store_name_clean','store_name_clean', method='jarowinkler', label = 'jarowinkler_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute levenshtein distance for addresses\n",
    "compare.string('address_clean', 'address_clean', method = 'levenshtein', label = 'levenshtein_address')\n",
    "\n",
    "#we want exact matches for city names\n",
    "compare.exact('city_clean', 'city_clean', label='city_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually compute the record pairs, we need to call the `compute` method. This will output exactly what we want to see: each potential pairing when blocked on `zipcode`, with corresponding values for our different comparative metrics we've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute record pairing scores\n",
    "features = compare.compute(pairs2, df_total, df_approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Once we have our comparison measures, we need to classify the measure in matches and non matches for non-exact pairings (Levenshtein and Jarowinkler). A rule-based approach would be to say if the similarity of our indicators is 0.85 or higher we consider this a match, everything else we won't match. This decision need to be made by the analyst. We're going to use .85 for all of our distance computations simply because it is considered to be a standard in the field.\n",
    "\n",
    "> In practice, you should examine matches around the thresholds you are considering to make sure the threshold lines up with how you theoretically view a match. Different methods return different results, so ideally, you would want to enact different thresholds based on the different comparative algorithms you are employing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impose threshold of .85\n",
    "features['levenshtein_name'] = [1 if v > .85 else 0 for v in features['levenshtein_name']]\n",
    "features['jarowinkler_name'] = [1 if v > .85 else 0 for v in features['jarowinkler_name']]\n",
    "features['levenshtein_address'] = [1 if v > .85 else 0 for v in features['levenshtein_address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to decide which stores are the same between the two tables. Let's see the comparison results by seeing the distribution of scores (0-5 for the counts of 1 for the five measures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrarily, let's say that all comparisons with at least 3 metrics scored as a 1 are matches. Let's subset to just those matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[features.sum(axis=1) >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of classiying records is the Fellegi Sunter Method. If Fellegi Sunter is used to classify record pairs, you would follow all the step we have done so far. However, now, we would estimate probabilities to construct weights. These weights will then be applied during the classification to give certain characteristics more importance. For example, we are more certain that very unique names are a match than Bob Millers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fellegi Sunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's assume the rows above are our matches\n",
    "matches = features[features.sum(axis=1) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features[features.sum(axis=1) >= 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Training Data and index\n",
    "ml_pairs = matches[0:4000]\n",
    "ml_matches_index = ml_pairs.index & pairs2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier is a probabilistic classifier. The probabilistic record linkage framework by Fellegi and Sunter (1969) is the most well-known probabilistic classification method for record linkage. Later, it was proved that the Fellegi and Sunter method is mathematically equivalent to the Naive Bayes method in case of assuming independence between comparison variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the classifier\n",
    "nb = rl.NaiveBayesClassifier()\n",
    "nb.fit(ml_pairs, ml_matches_index)\n",
    "\n",
    "## Predict the match status for all record pairs\n",
    "result_nb = nb.predict(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "The last step is to evaluate the results of the record linkage. We will cover this in more detail in the machine learning session. This is just for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion matrix\n",
    "conf_nb = rl.confusion_matrix(ml_pairs, result_nb, len(matches))\n",
    "conf_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precision and Accuracy\n",
    "precision = rl.precision(conf_nb)\n",
    "accuracy = rl.accuracy(conf_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precision and Accuracy\n",
    "print(precision)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The F-score for this classification is\n",
    "rl.fscore(conf_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Readings\n",
    "\n",
    "### Parsing\n",
    "\n",
    "* Python online documentation: https://docs.python.org/2/library/string.html#deprecated-string-functions\n",
    "* Python 2.7 Tutorial(Splitting and Joining Strings): http://www.pitt.edu/~naraehan/python2/split_join.html\n",
    "\n",
    "### Regular Expression\n",
    "\n",
    "* Python documentation: https://docs.python.org/2/library/re.html#regular-expression-syntax\n",
    "* Online regular expression tester (good for learning): http://regex101.com/\n",
    "\n",
    "### String Comparators\n",
    "\n",
    "* GitHub page of jellyfish: https://github.com/jamesturk/jellyfish\n",
    "* Different distances that measure the differences between strings:\n",
    "    - Levenshtein distance: https://en.wikipedia.org/wiki/Levenshtein_distance\n",
    "    - Damerau–Levenshtein distance: https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\n",
    "    - Jaro–Winkler distance: https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\n",
    "    - Hamming distance: https://en.wikipedia.org/wiki/Hamming_distance\n",
    "    - Match rating approach: https://en.wikipedia.org/wiki/Match_rating_approach\n",
    "\n",
    "### Fellegi-Sunter Record Linkage \n",
    "\n",
    "* Introduction to Probabilistic Record Linkage: http://www.bristol.ac.uk/media-library/sites/cmm/migrated/documents/problinkage.pdf\n",
    "* Paper Review: https://www.cs.umd.edu/class/spring2012/cmsc828L/Papers/HerzogEtWires10.pdf\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-ada",
   "language": "python",
   "name": "py3-ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "728px",
    "left": "0px",
    "right": "1021px",
    "top": "110px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
